== ASCII data options ==

Not yet implemented

By default, the .data contains the "data-like" lines of the .out file - lines that start with an integer with no preceding spaces.
* <code>dataLineRegex</code> The default is <code>^[0-9].*</code>.  
* <code>dataLineNormalizerRegex</code> 
* <code>dataLineNormalizerReplace</code>
Any line matching <code>dataLineRegex</code> in the response from the server for a given URL will appear in the .data file.  If both are specified, <code>dataLineNormalizerRegex</code> and <code>dataLineNormalizerReplace</code> are used as below to modify one or more contiguous data lines. 
<source lang="javascript">
fileline.toString()
    .replace(dataLineNormalizerRegex,dataLineNormalizerReplace)
    .split("\n")
    .filter(function(line){return line.search(dataLineRegex)!=-1;})
    .join("\n") + "\n";
</source>
=== Example: Testing a regular expression ===
For verifying regular expressions (for interactive regular expression creation and debugging, see [http://regexpal.com/]), open Chrome or Firefox's debugger and enter values for the first four variables given below.
<source lang="javascript">
fileline      = "";
dataLineRegex = "";
dataLineNormalizerRegex   = "";
dataLineNormalizerReplace = "";
fileline.toString()
    .replace(dataLineNormalizerRegex,dataLineNormalizerReplace)
    .split("\n")
    .filter(function(line){return line.search(dataLineRegex)!=-1;})
    .join("\n") + "\n";
</source>

=== Example: removing bad lines ===

=== Example: data span multiple lines ===
Note that URLs that return ASCII data that spans multiple contiguous lines can be have one or more lines combined.  For example,
<source lang="javascript">
filemultilines1  = "1980    01      02      00      14      00      1\nCMO     -28     13      13";
filemultilines2  = "1980    01      02      00      14      00      1\nCMO     -28     13      13";
filemultiline    = filemultilines1 + "\n" + filemultilines2;
dataLineRegex    = new RegExp(/^([\d]+)\s+([\d]+)\s+([\d]+)\s+([\d]+)\s+([\d]+)\s+([\d]+)\s+([\d]+)/);
dataLineNormalizerRegex   = new RegExp(/\n([a-zA-Z]+)\s+([\d-]+)\s([\d-]+)\s([\d-]+)/g);
dataLineNormalizerReplace = " $2 $3 $4";
twolines = 
filemultiline.toString()
    .replace(dataLineNormalizerRegex,dataLineNormalizerReplace)
    .split("\n")
    .filter(function(line){return line.search(dataLineRegex)!=-1;})
    .join("\n") + "\n";
console.log(filemultilines);
// 1980    01      02      00      14      00      1
// CMO     -28     13      13
// 1980    01      02      00      14      00      1
// CMO     -28     13      13
console.log(twolines);
// 1980    01      02      00      14      00      1 -28 13 13
// 1980    01      02      00      15      00      1 -23 10 9
</source>


Unit tests

curl "http://localhost:8000/sync?includeMeta=true&source=http://cdaweb.gsfc.nasa.gov/tmp/ws18979180951/ac_h1_mfi.txt"
curl "http://localhost:8000/sync?includeMeta=true&forceUpdate=true&source=http://cdaweb.gsfc.nasa.gov/tmp/ws18979180951/ac_h1_mfi.txt"

curl -d "includeMeta=true&source=http%3A%2F%2Fcdaweb.gsfc.nasa.gov%2FWS%2Fcdasr%2F1%2Fdataviews%2Fsp_phys%2Fdatasets%2FAC_H1_MFI%2Fdata%2F20050101T000000Z%2C20050102T000000Z%2FMagnitude%3Fformat%3Dtext" "http://localhost:8000/sync"
curl -d "includeMeta=true" "http://localhost:8000/sync?source=http%3A%2F%2Fcdaweb.gsfc.nasa.gov%2FWS%2Fcdasr%2F1%2Fdataviews%2Fsp_phys%2Fdatasets%2FAC_H1_MFI%2Fdata%2F20050101T000000Z%2C20050102T000000Z%2FMagnitude%3Fformat%3Dtext"

curl -d "includeMeta=true&forceUpdate=true&source=http%3A%2F%2Fcdaweb.gsfc.nasa.gov%2FWS%2Fcdasr%2F1%2Fdataviews%2Fsp_phys%2Fdatasets%2FAC_H1_MFI%2Fdata%2F20050101T000000Z%2C20050102T000000Z%2FMagnitude%3Fformat%3Dtext" "http://localhost:8000/sync"
curl -d "includeMeta=true&return=json&forceUpdate=false" "http://localhost:8000/sync?source=http%3A%2F%2Fcdaweb.gsfc.nasa.gov%2FWS%2Fcdasr%2F1%2Fdataviews%2Fsp_phys%2Fdatasets%2FAC_H1_MFI%2Fdata%2F20050101T000000Z%2C20050102T000000Z%2FMagnitude%3Fformat%3Dtext"


# Add parameters CONCURRENCY = 20, TIMEOUT = 20000, and MAXCONNECTION = 1000 to
datacache.sh.

Max node process is 1.9 GB => max file size = 1900/20 = 95 MB since all files are held in memory.

# Write keepversions() in util.js.  It reads keepversions.txt, which contains regular 
expressions for urls that should be versioned.

# Document servers.txt.  report.htm uses is.  Allow report? to take an input of servers to test.
/report?servers=datacache.org/sync,localhost:8080/sync, localhost:8081/sync&source=...

# Add example of changing file to documentation
curl "http://localhost:8000/sync?forceUpdate=true&source=http://localhost:8000/demo/changingfile.txt"

# Create option for return=bin.  By default it replaces "-" and ":" with spaces
and writes IEEE 64-bit LE Floating Point numbers.  Add recordsPerLine in JSON
output and numberOfRecords.

# Allow input of time2info(line) that returns [timeInteger,timeUnit,ISO 8601
Time] when time integer is computed from timeZero. Use this to compute
startTime, stopTime, timeUnit for each granule.

# Create option for return=binmeta.  Return startTime, stopTime, timeUnit
(smallest in all files), recordsPerLine, numberOfRecords, responseSize, and
meta, and metaJSON if it exists.

# Allow option of input of timeFormat %Y %m %d, etc..  Use this to add startTime
and stopTime to JSON.

# If time stamps are not fractional (%Y [%m %d %h %m %s]), compute required
timeUnit to preserve timestamps when converted to integers.

# If return=bin and timeFormat is given time to ms.  If timeUnit is given,
convert time to time since start.  When streaming, will need to correct times by
finding smallest time unit.

# If return=binmeta return startTime, stopTime, timeUnit, recordsPerLine,
numberOfRecords, responseSize, and meta, and metaJSON if it exists.
